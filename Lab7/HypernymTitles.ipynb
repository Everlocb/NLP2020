{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hMo3kj3LC3rA"
   },
   "source": [
    "#### Lab 7 \n",
    "#### Rouge Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obigo_n1C3rB",
    "outputId": "5a52f044-6ee2-4495-d030-b5253dbfd1db"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz \n",
    "import ipywidgets as widgets\n",
    "import pprint\n",
    "from ipywidgets import interact, interact_manual\n",
    "import re\n",
    "__PATH__ = \"./data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\n"
     ]
    }
   ],
   "source": [
    "cd C:\\\\Users\\\\User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UWQysSWC3rG",
    "outputId": "48a9bae7-de24-44c9-b11d-215646ae514b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qg2mYAm3C3rI",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>updatedDate</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>metaData</th>\n",
       "      <th>downloadLink</th>\n",
       "      <th>filePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/1407.6950v1</td>\n",
       "      <td>2014-07-24T16:56:39Z</td>\n",
       "      <td>2014-07-24T16:56:39Z</td>\n",
       "      <td>How,whenAndHowMuchACardDeckIsWellShuffled.pdf</td>\n",
       "      <td>The Thesis Consider The Mixing Of Few  3 4  ...</td>\n",
       "      <td>Benjamin Isac Fargion</td>\n",
       "      <td>cs.DM</td>\n",
       "      <td>Italian Thesis In Engeenering Computer, 26 Feb...</td>\n",
       "      <td>http://arxiv.org/pdf/1407.6950v1.pdf</td>\n",
       "      <td>./files/How,whenAndHowMuchACardDeckIsWellShuff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/0907.0618v1</td>\n",
       "      <td>2009-07-03T12:35:10Z</td>\n",
       "      <td>2009-07-03T12:35:10Z</td>\n",
       "      <td>QuantumIsometryGroups.pdf</td>\n",
       "      <td>This Thesis Contains The Formulation And Com...</td>\n",
       "      <td>Jyotishman Bhowmick</td>\n",
       "      <td>math.OA</td>\n",
       "      <td>Thesis</td>\n",
       "      <td>http://arxiv.org/pdf/0907.0618v1.pdf</td>\n",
       "      <td>./files/QuantumIsometryGroups.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/1806.09601v2</td>\n",
       "      <td>2018-07-14T17:06:27Z</td>\n",
       "      <td>2018-06-25T17:55:59Z</td>\n",
       "      <td>ComputationAndBoundingOfFolkmanNumbers.pdf</td>\n",
       "      <td>Phd Thesis Under The Supervision Of Professo...</td>\n",
       "      <td>Aleksandar Bikov</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>PhD Thesis</td>\n",
       "      <td>http://arxiv.org/pdf/1806.09601v2.pdf</td>\n",
       "      <td>./files/ComputationAndBoundingOfFolkmanNumbers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/1905.03014v1</td>\n",
       "      <td>2019-05-08T11:47:34Z</td>\n",
       "      <td>2019-05-08T11:47:34Z</td>\n",
       "      <td>OnChurch'sThesisInCubicalAssemblies.pdf</td>\n",
       "      <td>We Show That Church's Thesis, The Axiom Stat...</td>\n",
       "      <td>Andrew Swan, Taichi Uemura,</td>\n",
       "      <td>math.LO</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/1905.03014v1.pdf</td>\n",
       "      <td>./files/OnChurch'sThesisInCubicalAssemblies.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/1901.04911v1</td>\n",
       "      <td>2019-01-15T16:24:07Z</td>\n",
       "      <td>2019-01-15T16:24:07Z</td>\n",
       "      <td>UnconstrainedChurchTuringThesisCannotPossiblyB...</td>\n",
       "      <td>The Church Turing Thesis Asserts That If A P...</td>\n",
       "      <td>Yuri Gurevich</td>\n",
       "      <td>cs.LO</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/1901.04911v1.pdf</td>\n",
       "      <td>./files/UnconstrainedChurchTuringThesisCannotP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id           updatedDate  \\\n",
       "0   http://arxiv.org/abs/1407.6950v1  2014-07-24T16:56:39Z   \n",
       "1   http://arxiv.org/abs/0907.0618v1  2009-07-03T12:35:10Z   \n",
       "2  http://arxiv.org/abs/1806.09601v2  2018-07-14T17:06:27Z   \n",
       "3  http://arxiv.org/abs/1905.03014v1  2019-05-08T11:47:34Z   \n",
       "4  http://arxiv.org/abs/1901.04911v1  2019-01-15T16:24:07Z   \n",
       "\n",
       "          publishedDate                                              title  \\\n",
       "0  2014-07-24T16:56:39Z      How,whenAndHowMuchACardDeckIsWellShuffled.pdf   \n",
       "1  2009-07-03T12:35:10Z                          QuantumIsometryGroups.pdf   \n",
       "2  2018-06-25T17:55:59Z         ComputationAndBoundingOfFolkmanNumbers.pdf   \n",
       "3  2019-05-08T11:47:34Z            OnChurch'sThesisInCubicalAssemblies.pdf   \n",
       "4  2019-01-15T16:24:07Z  UnconstrainedChurchTuringThesisCannotPossiblyB...   \n",
       "\n",
       "                                             summary  \\\n",
       "0    The Thesis Consider The Mixing Of Few  3 4  ...   \n",
       "1    This Thesis Contains The Formulation And Com...   \n",
       "2    Phd Thesis Under The Supervision Of Professo...   \n",
       "3    We Show That Church's Thesis, The Axiom Stat...   \n",
       "4    The Church Turing Thesis Asserts That If A P...   \n",
       "\n",
       "                        authors category  \\\n",
       "0         Benjamin Isac Fargion    cs.DM   \n",
       "1           Jyotishman Bhowmick  math.OA   \n",
       "2              Aleksandar Bikov  math.CO   \n",
       "3  Andrew Swan, Taichi Uemura,   math.LO   \n",
       "4                 Yuri Gurevich    cs.LO   \n",
       "\n",
       "                                            metaData  \\\n",
       "0  Italian Thesis In Engeenering Computer, 26 Feb...   \n",
       "1                                             Thesis   \n",
       "2                                         PhD Thesis   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "                            downloadLink  \\\n",
       "0   http://arxiv.org/pdf/1407.6950v1.pdf   \n",
       "1   http://arxiv.org/pdf/0907.0618v1.pdf   \n",
       "2  http://arxiv.org/pdf/1806.09601v2.pdf   \n",
       "3  http://arxiv.org/pdf/1905.03014v1.pdf   \n",
       "4  http://arxiv.org/pdf/1901.04911v1.pdf   \n",
       "\n",
       "                                            filePath  \n",
       "0  ./files/How,whenAndHowMuchACardDeckIsWellShuff...  \n",
       "1                  ./files/QuantumIsometryGroups.pdf  \n",
       "2  ./files/ComputationAndBoundingOfFolkmanNumbers...  \n",
       "3    ./files/OnChurch'sThesisInCubicalAssemblies.pdf  \n",
       "4  ./files/UnconstrainedChurchTuringThesisCannotP...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(__PATH__,sep=\";\",header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XG1xtU4xC3rK"
   },
   "source": [
    "#### Preprocessing the title to list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRgalGvEC3rL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('much', 'card', 'deck', 'well', 'shuffled'),\n",
       " ('quantum', 'isometry', 'groups'),\n",
       " ('computation', 'bounding', 'folkman', 'numbers'),\n",
       " ('church', 'thesis', 'cubical', 'assemblies'),\n",
       " ('unconstrained', 'church', 'turing', 'thesis', 'cannot', 'possibly', 'true'),\n",
       " ('algebraic',\n",
       "  'relaxations',\n",
       "  'hardness',\n",
       "  'results',\n",
       "  'polynomial',\n",
       "  'optimization',\n",
       "  'lyapunov',\n",
       "  'analysis'),\n",
       " ('resolving',\n",
       "  'complexity',\n",
       "  'fundamental',\n",
       "  'problems',\n",
       "  'computational',\n",
       "  'social',\n",
       "  'choice'),\n",
       " ('pa',\n",
       "  'instantiationally',\n",
       "  'complete',\n",
       "  'algorithmically',\n",
       "  'incomplete',\n",
       "  'alternative',\n",
       "  'interpretation',\n",
       "  'goedelian',\n",
       "  'incompleteness',\n",
       "  'church',\n",
       "  'thesis',\n",
       "  'links',\n",
       "  'formal',\n",
       "  'logic',\n",
       "  'computability'),\n",
       " ('numerical',\n",
       "  'modeling',\n",
       "  'fluid',\n",
       "  'flow',\n",
       "  'porous',\n",
       "  'media',\n",
       "  'modelowanie',\n",
       "  'numeryczne',\n",
       "  'transportu',\n",
       "  'plynow',\n",
       "  'przez',\n",
       "  'osrodki',\n",
       "  'porowate'),\n",
       " ('threebranes', 'theory'),\n",
       " ('spin',\n",
       "  'torque',\n",
       "  'nano',\n",
       "  'oscillators',\n",
       "  'memristors',\n",
       "  'multi',\n",
       "  'functional',\n",
       "  'nanodevices',\n",
       "  'advanced',\n",
       "  'computing'),\n",
       " ('effectuses', 'categorical', 'quantum', 'foundations'),\n",
       " ('hypercomputation',\n",
       "  'towards',\n",
       "  'extension',\n",
       "  'classical',\n",
       "  'notion',\n",
       "  'computability'),\n",
       " ('estimation', 'use', 'statistical', 'modelling', 'information', 'retrieval'),\n",
       " ('combinatorial', 'koszul', 'homology', 'computations', 'applications'),\n",
       " ('effective', 'banach', 'spaces'),\n",
       " ('computing',),\n",
       " ('first', 'principles', 'study', 'intein', 'reaction', 'mechanisms'),\n",
       " ('guarding', 'searching', 'polyhedra'),\n",
       " ('adaptation', 'self', 'organization', 'evolutionary', 'algorithms')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = list(df['title'].apply(\n",
    "    lambda t : \n",
    "        tuple(\n",
    "            filter(lambda e:not e in stopwords.words('english'),\n",
    "                map(lambda e:e.lower(),\n",
    "                       re.findall('([A-Z]{1}[a-z]+)',t.replace('.pdf','')))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "titles[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojN89e-cC3rN"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for title in titles[:25]:\n",
    "    synsets = {}\n",
    "    for word in title:\n",
    "        synsets[word]=[synset for synset in wn.synsets(word)]\n",
    "    res[title] = synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "\n",
      "(('algebraic', 'relaxations', 'hardness', 'results', 'polynomial', 'optimization', 'lyapunov', 'analysis'), {'algebraic': [Synset('algebraic.a.01')], 'relaxations': [Synset('relaxation.n.01'), Synset('relaxation.n.02'), Synset('easiness.n.01'), Synset('relaxation.n.04'), Synset('rest.n.02'), Synset('relaxation.n.06'), Synset('liberalization.n.01')], 'hardness': [Synset('hardness.n.01'), Synset('hardness.n.02'), Synset('unfeelingness.n.01'), Synset('hardness.n.04'), Synset('severity.n.04')], 'results': [Synset('consequence.n.01'), Synset('solution.n.02'), Synset('result.n.03'), Synset('resultant_role.n.01'), Synset('result.v.01'), Synset('leave.v.07'), Synset('result.v.03')], 'polynomial': [Synset('polynomial.n.01'), Synset('polynomial.a.01')], 'optimization': [Synset('optimization.n.01')], 'lyapunov': [], 'analysis': [Synset('analysis.n.01'), Synset('analysis.n.02'), Synset('analysis.n.03'), Synset('analysis.n.04'), Synset('analysis.n.05'), Synset('psychoanalysis.n.01')]})\n"
     ]
    }
   ],
   "source": [
    "print(len(reslist))\n",
    "print()\n",
    "print(reslist[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_classes(synset):\n",
    "    hyps = set()\n",
    "    while True:\n",
    "        try:\n",
    "            synset = synset.hypernyms()[-1]\n",
    "#             print(synset)\n",
    "            hyps.add(synset)\n",
    "        except IndexError:\n",
    "            break\n",
    "    return hyps\n",
    "\n",
    "def extract_hypornyms_en(a):\n",
    "    hypornyms_en = set()\n",
    "    for word in a:\n",
    "        # find the hypernyms of the word\n",
    "        # word = wn.synset(word)\n",
    "        try:\n",
    "            word_synset0 = wn.synsets(word)[0]\n",
    "            hyps_buff = get_parent_classes(word_synset0)\n",
    "            for h in hyps_buff:\n",
    "                hypornyms_en.add(h)\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return hypornyms_en\n",
    "\n",
    "def f1measure(a, b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    # missed part\n",
    "    overlap = set()\n",
    "    overlap_hyp_cnt = 0\n",
    "    overlap = a.intersection(b)\n",
    "    overlap_hyp_cnt = len(overlap) \n",
    "    \n",
    "    recl = overlap_hyp_cnt/len(a)\n",
    "    prec = overlap_hyp_cnt/len(b)\n",
    "    \n",
    "    if len(overlap) == 0:\n",
    "        return 0, overlap\n",
    "    else:\n",
    "        return 2*recl*prec/(recl+prec), overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.f1measure(a, b)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsBev1EcC3rP"
   },
   "outputs": [],
   "source": [
    "lang = 'eng'\n",
    "\n",
    "def distance(a,b):\n",
    "    ### Put your code here\n",
    "    ### В переменной synsets помимо нормализованного заголовка хранятся синсеты для каждого токена из заголовка.\n",
    "    ### у синсетов есть гиперонимы про то как из брать здесь\n",
    "    ### Если у токенов заголовков есть общие гиперонимы тогда заголовки связаны несмотря на то что слова разные\n",
    "    \n",
    "    a = set(a) \n",
    "    b = set(b) \n",
    "    f1score, overlap = f1measure(a, b)\n",
    "    a = a - overlap\n",
    "    b = b - overlap\n",
    "    \n",
    "    if len(a) == 0 or len(b) == 0:\n",
    "        return 1.0 - f1score\n",
    "    \n",
    "    buff_a = {}\n",
    "    buff_b = {}\n",
    "    \n",
    "    if lang == 'eng':\n",
    "        buff_a = extract_hypornyms_en(a)\n",
    "        buff_b = extract_hypornyms_en(b)\n",
    "        \n",
    "    overlap_hyp_cnt = 0\n",
    "#for word in a:\n",
    "    #    for wordb in b:\n",
    "    #        if len(buff_a[word].intersection(buff_b[wordb])) > 0:\n",
    "    #            overlap_hyp_cnt += 1\n",
    "    \n",
    "    overlap = a.intersection(b)\n",
    "    overlap_hyp_cnt = len(overlap) \n",
    "    \n",
    "    recl_hyp = overlap_hyp_cnt/len(a)\n",
    "    prec_hyp = overlap_hyp_cnt/len(b)\n",
    "    f1score_hyp = 2*recl_hyp/(recl_hyp + prec_hyp) if overlap_hyp_cnt > 0 else 0\n",
    "    f1res = (2*f1score+f1score_hyp)/3\n",
    "    return (1.0 - f1res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "buff = list(res.items())\n",
    "dist = np.zeros((len(buff),len(buff)))\n",
    "for lli,ll in enumerate(buff):\n",
    "    for rri,rr in enumerate(buff):\n",
    "        dist[lli,rri] = distance(ll[0], rr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('much', 'card', 'deck', 'well', 'shuffled'),\n",
       "  {'much': [Synset('much.n.01'),\n",
       "    Synset('much.a.01'),\n",
       "    Synset('much.r.01'),\n",
       "    Synset('much.r.02'),\n",
       "    Synset('a_lot.r.01'),\n",
       "    Synset('much.r.04'),\n",
       "    Synset('much.r.05')],\n",
       "   'card': [Synset('card.n.01'),\n",
       "    Synset('card.n.02'),\n",
       "    Synset('card.n.03'),\n",
       "    Synset('card.n.04'),\n",
       "    Synset('wag.n.01'),\n",
       "    Synset('poster.n.01'),\n",
       "    Synset('calling_card.n.02'),\n",
       "    Synset('card.n.08'),\n",
       "    Synset('menu.n.01'),\n",
       "    Synset('batting_order.n.01'),\n",
       "    Synset('circuit_board.n.01'),\n",
       "    Synset('tease.v.07'),\n",
       "    Synset('card.v.02')],\n",
       "   'deck': [Synset('deck.n.01'),\n",
       "    Synset('deck.n.02'),\n",
       "    Synset('pack_of_cards.n.01'),\n",
       "    Synset('deck.n.04'),\n",
       "    Synset('deck.v.01'),\n",
       "    Synset('deck.v.02'),\n",
       "    Synset('deck.v.03')],\n",
       "   'well': [Synset('well.n.01'),\n",
       "    Synset('well.n.02'),\n",
       "    Synset('well.n.03'),\n",
       "    Synset('well.n.04'),\n",
       "    Synset('well.n.05'),\n",
       "    Synset('well.v.01'),\n",
       "    Synset('well.a.01'),\n",
       "    Synset('good.s.13'),\n",
       "    Synset('well.s.03'),\n",
       "    Synset('well.r.01'),\n",
       "    Synset('well.r.02'),\n",
       "    Synset('well.r.03'),\n",
       "    Synset('well.r.04'),\n",
       "    Synset('well.r.05'),\n",
       "    Synset('well.r.06'),\n",
       "    Synset('well.r.07'),\n",
       "    Synset('well.r.08'),\n",
       "    Synset('well.r.09'),\n",
       "    Synset('well.r.10'),\n",
       "    Synset('well.r.11'),\n",
       "    Synset('well.r.12'),\n",
       "    Synset('well.r.13')],\n",
       "   'shuffled': [Synset('shuffle.v.01'),\n",
       "    Synset('shuffle.v.02'),\n",
       "    Synset('shuffle.v.03')]})]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buff[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVW9NVFmC3rR"
   },
   "source": [
    "#### Top ten closest articles with fuzzy metrics of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "b06d56940d7a4b33b49ac122f8055d9d"
     ]
    },
    "colab_type": "code",
    "id": "PJfKkP_sC3rS",
    "outputId": "e3ddbefa-ea40-4464-f87b-45690e241fce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20f3ef9120f4766a6bcb7c605898128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='ind', max=24), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(ind=(0,len(buff)-1,1))\n",
    "def h(ind=0):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print(' '.join(buff[ind][0]))\n",
    "    pp.pprint([buff[i][0] for i in dist[ind][:].argsort()[1:11]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "fd9b9f3aff4a4b518fb0345303c63386"
     ]
    },
    "colab_type": "code",
    "id": "hQ3fW1fSC3rU",
    "outputId": "af83791b-ef9e-4c5a-bf6a-a1be03881661"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5908f742e93b4e27885b45b95c134b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='ind', max=24), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(ind=(0,len(buff)-1,1))\n",
    "def hypernyms(ind=0):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print(' '.join(buff[ind][0]))\n",
    "    pp.pprint(buff[ind][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HypernymTitles.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
